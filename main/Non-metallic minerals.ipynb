{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "import pytse_client as tse\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from timeit import default_timer as timer\n",
    "from keras.layers import LSTM, Dense, Dropout,Convolution1D, Activation, MaxPooling1D, Flatten,Input\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from matplotlib.pylab import rcParams\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score,mean_absolute_error\n",
    "from math import sqrt\n",
    "import math\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "from tqdm.keras import TqdmCallback\n",
    "#rcParams[\"figure.figsize\"] = (20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>adjClose</th>\n",
       "      <th>Profitability of the company</th>\n",
       "      <th>Number of Trade</th>\n",
       "      <th>count</th>\n",
       "      <th>close</th>\n",
       "      <th>p/e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>6679876</td>\n",
       "      <td>2422</td>\n",
       "      <td>2</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>11.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>2757.0</td>\n",
       "      <td>57876000</td>\n",
       "      <td>21000</td>\n",
       "      <td>3</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>11.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-19</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>79924000</td>\n",
       "      <td>29000</td>\n",
       "      <td>4</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>11.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-03-01</td>\n",
       "      <td>2753.0</td>\n",
       "      <td>2753.0</td>\n",
       "      <td>2753.0</td>\n",
       "      <td>2753.0</td>\n",
       "      <td>101861000</td>\n",
       "      <td>37000</td>\n",
       "      <td>4</td>\n",
       "      <td>2753.0</td>\n",
       "      <td>11.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-03-04</td>\n",
       "      <td>2752.0</td>\n",
       "      <td>2752.0</td>\n",
       "      <td>2752.0</td>\n",
       "      <td>2753.0</td>\n",
       "      <td>42105600</td>\n",
       "      <td>15300</td>\n",
       "      <td>4</td>\n",
       "      <td>2752.0</td>\n",
       "      <td>11.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>2019-02-23</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>2830.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>2779.0</td>\n",
       "      <td>2547636877</td>\n",
       "      <td>916768</td>\n",
       "      <td>249</td>\n",
       "      <td>2770.0</td>\n",
       "      <td>10.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2778.0</td>\n",
       "      <td>2885.0</td>\n",
       "      <td>2778.0</td>\n",
       "      <td>2821.0</td>\n",
       "      <td>3445789359</td>\n",
       "      <td>1221437</td>\n",
       "      <td>258</td>\n",
       "      <td>2840.0</td>\n",
       "      <td>10.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>2019-02-25</td>\n",
       "      <td>2799.0</td>\n",
       "      <td>2845.0</td>\n",
       "      <td>2799.0</td>\n",
       "      <td>2820.0</td>\n",
       "      <td>4201181353</td>\n",
       "      <td>1489545</td>\n",
       "      <td>232</td>\n",
       "      <td>2830.0</td>\n",
       "      <td>10.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>2820.0</td>\n",
       "      <td>2820.0</td>\n",
       "      <td>2679.0</td>\n",
       "      <td>2760.0</td>\n",
       "      <td>3715870003</td>\n",
       "      <td>1346258</td>\n",
       "      <td>192</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>10.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2019-02-27</td>\n",
       "      <td>2866.0</td>\n",
       "      <td>2866.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>2816.0</td>\n",
       "      <td>1874710455</td>\n",
       "      <td>665640</td>\n",
       "      <td>183</td>\n",
       "      <td>2818.0</td>\n",
       "      <td>10.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1565 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date    open    high     low  adjClose  \\\n",
       "0     2009-01-05  2758.0  2758.0  2758.0    2758.0   \n",
       "1     2009-01-13  2756.0  2756.0  2756.0    2757.0   \n",
       "2     2009-01-19  2756.0  2756.0  2756.0    2756.0   \n",
       "3     2009-03-01  2753.0  2753.0  2753.0    2753.0   \n",
       "4     2009-03-04  2752.0  2752.0  2752.0    2753.0   \n",
       "...          ...     ...     ...     ...       ...   \n",
       "1560  2019-02-23  2720.0  2830.0  2720.0    2779.0   \n",
       "1561  2019-02-24  2778.0  2885.0  2778.0    2821.0   \n",
       "1562  2019-02-25  2799.0  2845.0  2799.0    2820.0   \n",
       "1563  2019-02-26  2820.0  2820.0  2679.0    2760.0   \n",
       "1564  2019-02-27  2866.0  2866.0  2700.0    2816.0   \n",
       "\n",
       "      Profitability of the company  Number of Trade  count   close    p/e  \n",
       "0                          6679876             2422      2  2758.0  11.67  \n",
       "1                         57876000            21000      3  2756.0  11.67  \n",
       "2                         79924000            29000      4  2756.0  11.67  \n",
       "3                        101861000            37000      4  2753.0  11.67  \n",
       "4                         42105600            15300      4  2752.0  11.67  \n",
       "...                            ...              ...    ...     ...    ...  \n",
       "1560                    2547636877           916768    249  2770.0  10.53  \n",
       "1561                    3445789359          1221437    258  2840.0  10.53  \n",
       "1562                    4201181353          1489545    232  2830.0  10.53  \n",
       "1563                    3715870003          1346258    192  2810.0  10.53  \n",
       "1564                    1874710455           665640    183  2818.0  10.53  \n",
       "\n",
       "[1565 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Mineral=pd.read_csv('tickers_data/كرازي.csv')\n",
    "display(Mineral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date    object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>2019-02-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>2019-02-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>2019-02-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>2019-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2019-02-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1565 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date\n",
       "0    2009-01-05\n",
       "1    2009-01-13\n",
       "2    2009-01-19\n",
       "3    2009-03-01\n",
       "4    2009-03-04\n",
       "...         ...\n",
       "1560 2019-02-23\n",
       "1561 2019-02-24\n",
       "1562 2019-02-25\n",
       "1563 2019-02-26\n",
       "1564 2019-02-27\n",
       "\n",
       "[1565 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#astype date in first code\n",
    "S=Mineral.iloc[:, 0:1]\n",
    "S1=pd.DataFrame(S)\n",
    "display(S1.dtypes)\n",
    "S1['date'] = S1['date'].astype('datetime64[ns]')\n",
    "S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>Profitability of the company</th>\n",
       "      <th>Number of Trade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>0.176200</td>\n",
       "      <td>0.175261</td>\n",
       "      <td>0.183042</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>0.175985</td>\n",
       "      <td>0.175048</td>\n",
       "      <td>0.182820</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.001471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2009-01-19</td>\n",
       "      <td>0.175985</td>\n",
       "      <td>0.175048</td>\n",
       "      <td>0.182820</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.002031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2009-03-01</td>\n",
       "      <td>0.175664</td>\n",
       "      <td>0.174728</td>\n",
       "      <td>0.182486</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.002591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2009-03-04</td>\n",
       "      <td>0.175557</td>\n",
       "      <td>0.174622</td>\n",
       "      <td>0.182375</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.001071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number        date     close      high       low  \\\n",
       "0       0  2009-01-05  0.176200  0.175261  0.183042   \n",
       "1       1  2009-01-13  0.175985  0.175048  0.182820   \n",
       "2       2  2009-01-19  0.175985  0.175048  0.182820   \n",
       "3       3  2009-03-01  0.175664  0.174728  0.182486   \n",
       "4       4  2009-03-04  0.175557  0.174622  0.182375   \n",
       "\n",
       "   Profitability of the company  Number of Trade  \n",
       "0                      0.000083         0.000170  \n",
       "1                      0.000716         0.001471  \n",
       "2                      0.000989         0.002031  \n",
       "3                      0.001261         0.002591  \n",
       "4                      0.000521         0.001071  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ind2 = pd.read_csv('tickers_data/finalMineralJoin4_data.csv')\n",
    "Ind2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop1=['number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>Profitability of the company</th>\n",
       "      <th>Number of Trade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>0.176200</td>\n",
       "      <td>0.175261</td>\n",
       "      <td>0.183042</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>0.175985</td>\n",
       "      <td>0.175048</td>\n",
       "      <td>0.182820</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.001471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-19</td>\n",
       "      <td>0.175985</td>\n",
       "      <td>0.175048</td>\n",
       "      <td>0.182820</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.002031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-03-01</td>\n",
       "      <td>0.175664</td>\n",
       "      <td>0.174728</td>\n",
       "      <td>0.182486</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.002591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-03-04</td>\n",
       "      <td>0.175557</td>\n",
       "      <td>0.174622</td>\n",
       "      <td>0.182375</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.001071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>2019-02-23</td>\n",
       "      <td>0.177485</td>\n",
       "      <td>0.182932</td>\n",
       "      <td>0.178814</td>\n",
       "      <td>0.031537</td>\n",
       "      <td>0.064199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>0.184983</td>\n",
       "      <td>0.188792</td>\n",
       "      <td>0.185268</td>\n",
       "      <td>0.042655</td>\n",
       "      <td>0.085535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>2019-02-25</td>\n",
       "      <td>0.183912</td>\n",
       "      <td>0.184530</td>\n",
       "      <td>0.187604</td>\n",
       "      <td>0.052006</td>\n",
       "      <td>0.104310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>0.181769</td>\n",
       "      <td>0.181867</td>\n",
       "      <td>0.174252</td>\n",
       "      <td>0.045998</td>\n",
       "      <td>0.094276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2019-02-27</td>\n",
       "      <td>0.182626</td>\n",
       "      <td>0.186768</td>\n",
       "      <td>0.176588</td>\n",
       "      <td>0.023207</td>\n",
       "      <td>0.046613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1565 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     close      high       low  Profitability of the company  \\\n",
       "0     2009-01-05  0.176200  0.175261  0.183042                      0.000083   \n",
       "1     2009-01-13  0.175985  0.175048  0.182820                      0.000716   \n",
       "2     2009-01-19  0.175985  0.175048  0.182820                      0.000989   \n",
       "3     2009-03-01  0.175664  0.174728  0.182486                      0.001261   \n",
       "4     2009-03-04  0.175557  0.174622  0.182375                      0.000521   \n",
       "...          ...       ...       ...       ...                           ...   \n",
       "1560  2019-02-23  0.177485  0.182932  0.178814                      0.031537   \n",
       "1561  2019-02-24  0.184983  0.188792  0.185268                      0.042655   \n",
       "1562  2019-02-25  0.183912  0.184530  0.187604                      0.052006   \n",
       "1563  2019-02-26  0.181769  0.181867  0.174252                      0.045998   \n",
       "1564  2019-02-27  0.182626  0.186768  0.176588                      0.023207   \n",
       "\n",
       "      Number of Trade  \n",
       "0            0.000170  \n",
       "1            0.001471  \n",
       "2            0.002031  \n",
       "3            0.002591  \n",
       "4            0.001071  \n",
       "...               ...  \n",
       "1560         0.064199  \n",
       "1561         0.085535  \n",
       "1562         0.104310  \n",
       "1563         0.094276  \n",
       "1564         0.046613  \n",
       "\n",
       "[1565 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Ind2.drop(to_drop1,inplace=True, axis=1)\n",
    "Ind2.head()\n",
    "Ind2.tail()\n",
    "display(Ind2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>value</th>\n",
       "      <th>volume</th>\n",
       "      <th>close</th>\n",
       "      <th>p/e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>6679876</td>\n",
       "      <td>2422</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>11.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>57876000</td>\n",
       "      <td>21000</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>11.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2009-01-19</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>79924000</td>\n",
       "      <td>29000</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>11.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2009-03-01</td>\n",
       "      <td>2753.0</td>\n",
       "      <td>2753.0</td>\n",
       "      <td>2753.0</td>\n",
       "      <td>101861000</td>\n",
       "      <td>37000</td>\n",
       "      <td>2753.0</td>\n",
       "      <td>11.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2009-03-04</td>\n",
       "      <td>2752.0</td>\n",
       "      <td>2752.0</td>\n",
       "      <td>2752.0</td>\n",
       "      <td>42105600</td>\n",
       "      <td>15300</td>\n",
       "      <td>2752.0</td>\n",
       "      <td>11.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>1091</td>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>2631.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>2631.0</td>\n",
       "      <td>4369688998</td>\n",
       "      <td>1624795</td>\n",
       "      <td>2695.0</td>\n",
       "      <td>10.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>1092</td>\n",
       "      <td>2017-02-07</td>\n",
       "      <td>2695.0</td>\n",
       "      <td>2723.0</td>\n",
       "      <td>2660.0</td>\n",
       "      <td>3010735764</td>\n",
       "      <td>1118112</td>\n",
       "      <td>2688.0</td>\n",
       "      <td>10.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>1093</td>\n",
       "      <td>2017-02-08</td>\n",
       "      <td>2728.0</td>\n",
       "      <td>2728.0</td>\n",
       "      <td>2662.0</td>\n",
       "      <td>3776325913</td>\n",
       "      <td>1408556</td>\n",
       "      <td>2667.0</td>\n",
       "      <td>10.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>1094</td>\n",
       "      <td>2017-02-11</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>4214136493</td>\n",
       "      <td>1556757</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>10.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>1095</td>\n",
       "      <td>2017-02-12</td>\n",
       "      <td>2681.0</td>\n",
       "      <td>2718.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>3569078807</td>\n",
       "      <td>1322778</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>10.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1096 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      number        date    open    high     low       value   volume   close  \\\n",
       "0          0  2009-01-05  2758.0  2758.0  2758.0     6679876     2422  2758.0   \n",
       "1          1  2009-01-13  2756.0  2756.0  2756.0    57876000    21000  2756.0   \n",
       "2          2  2009-01-19  2756.0  2756.0  2756.0    79924000    29000  2756.0   \n",
       "3          3  2009-03-01  2753.0  2753.0  2753.0   101861000    37000  2753.0   \n",
       "4          4  2009-03-04  2752.0  2752.0  2752.0    42105600    15300  2752.0   \n",
       "...      ...         ...     ...     ...     ...         ...      ...     ...   \n",
       "1091    1091  2017-02-06  2631.0  2700.0  2631.0  4369688998  1624795  2695.0   \n",
       "1092    1092  2017-02-07  2695.0  2723.0  2660.0  3010735764  1118112  2688.0   \n",
       "1093    1093  2017-02-08  2728.0  2728.0  2662.0  3776325913  1408556  2667.0   \n",
       "1094    1094  2017-02-11  2680.0  2730.0  2680.0  4214136493  1556757  2700.0   \n",
       "1095    1095  2017-02-12  2681.0  2718.0  2680.0  3569078807  1322778  2700.0   \n",
       "\n",
       "        p/e  \n",
       "0     11.67  \n",
       "1     11.67  \n",
       "2     11.67  \n",
       "3     11.67  \n",
       "4     11.67  \n",
       "...     ...  \n",
       "1091  10.73  \n",
       "1092  10.73  \n",
       "1093  10.73  \n",
       "1094  10.73  \n",
       "1095  10.73  \n",
       "\n",
       "[1096 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load train data in third code\n",
    "Mineral_train=pd.read_csv('tickers_data/کرازی_train.csv')\n",
    "Mineral_train.shape\n",
    "Mineral_train.head(1096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>value</th>\n",
       "      <th>volume</th>\n",
       "      <th>close</th>\n",
       "      <th>p/e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>6679876</td>\n",
       "      <td>2422</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>11.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>57876000</td>\n",
       "      <td>21000</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>11.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-19</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>79924000</td>\n",
       "      <td>29000</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>11.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-03-01</td>\n",
       "      <td>2753.0</td>\n",
       "      <td>2753.0</td>\n",
       "      <td>2753.0</td>\n",
       "      <td>101861000</td>\n",
       "      <td>37000</td>\n",
       "      <td>2753.0</td>\n",
       "      <td>11.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-03-04</td>\n",
       "      <td>2752.0</td>\n",
       "      <td>2752.0</td>\n",
       "      <td>2752.0</td>\n",
       "      <td>42105600</td>\n",
       "      <td>15300</td>\n",
       "      <td>2752.0</td>\n",
       "      <td>11.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    open    high     low      value  volume   close    p/e\n",
       "0  2009-01-05  2758.0  2758.0  2758.0    6679876    2422  2758.0  11.67\n",
       "1  2009-01-13  2756.0  2756.0  2756.0   57876000   21000  2756.0  11.67\n",
       "2  2009-01-19  2756.0  2756.0  2756.0   79924000   29000  2756.0  11.67\n",
       "3  2009-03-01  2753.0  2753.0  2753.0  101861000   37000  2753.0  11.67\n",
       "4  2009-03-04  2752.0  2752.0  2752.0   42105600   15300  2752.0  11.67"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop1=['number']\n",
    "Mineral_train.drop(to_drop1,inplace=True, axis=1)\n",
    "Mineral_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose train data in third code\n",
    "training_set = Mineral_train.iloc[:, 2:3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization data in third code\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split x, y train in third code\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(21, 1096):\n",
    "    X_train.append(training_set_scaled[i-21:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape x train in third code\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17526103],\n",
       "       [0.17504794],\n",
       "       [0.17504794],\n",
       "       ...,\n",
       "       [0.17206478],\n",
       "       [0.17227786],\n",
       "       [0.17099936]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(training_set_scaled)\n",
    "training_set_scaled.max()\n",
    "#training_set_scaled.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(469, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read test data third\n",
    "Mineral_test=pd.read_csv('tickers_data/کرازی_test.csv')\n",
    "Mineral_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with 6 layer lstm\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=1)) # Prediction of the next closing value\n",
    "\n",
    "generations = 10 # The higher the value the better the result\n",
    "start_timer = timer()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)\n",
    "end_timer = timer()\n",
    "print(f'Time elapsed: {str(end_timer - start_timer)[:5]} sec.')\n",
    "print('Done training a model!')\n",
    "#model with 2 layer cnn\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution1D(64, 3, input_shape=(y_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "model2.add(Convolution1D(32, 3))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "model2.add(Flatten())\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model2.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with 6 layer lstm\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=1)) # Prediction of the next closing value\n",
    "\n",
    "generations = 10 # The higher the value the better the result\n",
    "start_timer = timer()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)\n",
    "end_timer = timer()\n",
    "print(f'Time elapsed: {str(end_timer - start_timer)[:5]} sec.')\n",
    "print('Done training a model!')\n",
    "#model with 3 layer cnn\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(LSTM(100, return_sequences=True))\n",
    "#model2.add(Dropout(0.2))\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(32, 3))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "model2.add(Flatten())\n",
    "#model2.add(Dense(1))\n",
    "#model.add(Activation('linear'))\n",
    "generations = 10\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model2.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0935 - mse: 0.0935 - mae: 0.2176 - mape: 77959.5731WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - 23s 285ms/step - loss: 0.0921 - mse: 0.0921 - mae: 0.2156 - mape: 78719.7649 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0748 - val_mape: 23.4544\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 2s 91ms/step - loss: 0.0173 - mse: 0.0173 - mae: 0.0909 - mape: 138820.0453 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0606 - val_mape: 19.0579\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 3s 109ms/step - loss: 0.0147 - mse: 0.0147 - mae: 0.0781 - mape: 19047.9060 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0519 - val_mape: 18.6484\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 3s 115ms/step - loss: 0.0135 - mse: 0.0135 - mae: 0.0781 - mape: 3247.8417 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0528 - val_mape: 19.5812\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 3s 131ms/step - loss: 0.0169 - mse: 0.0169 - mae: 0.0873 - mape: 36469.7508 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0624 - val_mape: 21.5602\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 3s 105ms/step - loss: 0.0144 - mse: 0.0144 - mae: 0.0806 - mape: 15351.2450 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0531 - val_mape: 18.9665\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 3s 105ms/step - loss: 0.0145 - mse: 0.0145 - mae: 0.0832 - mape: 66988.1477 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0500 - val_mape: 17.6516\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0754 - mape: 16873.6587 - val_loss: 0.0128 - val_mse: 0.0128 - val_mae: 0.0772 - val_mape: 26.4195\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 0.0095 - mse: 0.0095 - mae: 0.0705 - mape: 821.1330 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0609 - val_mape: 21.8811\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 0.0099 - mse: 0.0099 - mae: 0.0714 - mape: 1913.2719 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0514 - val_mape: 18.3002\n",
      "Time elapsed: 49.06 sec.\n",
      "Done training a model!\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_input'), name='conv1d_input', description=\"created by layer 'conv1d_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_input'), name='conv1d_input', description=\"created by layer 'conv1d_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "22/27 [=======================>......] - ETA: 0s - loss: 0.0992 - mse: 0.0992 - mae: 0.2076 - mape: 44177.7203WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_input'), name='conv1d_input', description=\"created by layer 'conv1d_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - 2s 19ms/step - loss: 0.0872 - mse: 0.0872 - mae: 0.1904 - mape: 39169.9790 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0667 - val_mape: 21.8942\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0501 - mape: 14766.0873 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0531 - val_mape: 18.2672\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0434 - mape: 37114.2696 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0520 - val_mape: 18.2034\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0471 - mape: 23461.5616 - val_loss: 0.0087 - val_mse: 0.0087 - val_mae: 0.0533 - val_mape: 18.5717\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0436 - mape: 22739.8255 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0582 - val_mape: 20.1575\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0437 - mape: 14054.9057 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0482 - val_mape: 15.9708\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0402 - mape: 4874.4676 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0477 - val_mape: 16.3740\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0402 - mape: 52623.2022 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0512 - val_mape: 17.6439\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0400 - mape: 6356.6937 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0535 - val_mape: 18.3704\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0390 - mape: 16402.1260 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0444 - val_mape: 14.7295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d740bcd910>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model with 6 layer lstm\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=1)) # Prediction of the next closing value\n",
    "\n",
    "generations = 10 # The higher the value the better the result\n",
    "start_timer = timer()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)\n",
    "end_timer = timer()\n",
    "print(f'Time elapsed: {str(end_timer - start_timer)[:5]} sec.')\n",
    "print('Done training a model!')\n",
    "#model with 4 layer cnn\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(32, 3))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "model2.add(Flatten())\n",
    "generations = 10\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model2.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with 6 layer lstm\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=1)) # Prediction of the next closing value\n",
    "\n",
    "generations = 10 # The higher the value the better the result\n",
    "start_timer = timer()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)\n",
    "end_timer = timer()\n",
    "print(f'Time elapsed: {str(end_timer - start_timer)[:5]} sec.')\n",
    "print('Done training a model!')\n",
    "#model with 5 layer cnn\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(32, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Flatten())\n",
    "generations = 10\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model2.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_6_input'), name='lstm_6_input', description=\"created by layer 'lstm_6_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_6_input'), name='lstm_6_input', description=\"created by layer 'lstm_6_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0922 - mse: 0.0922 - mae: 0.2242 - mape: 14471.6082WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_6_input'), name='lstm_6_input', description=\"created by layer 'lstm_6_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - 26s 259ms/step - loss: 0.0909 - mse: 0.0909 - mae: 0.2222 - mape: 16030.1961 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0903 - val_mape: 27.9625\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 3s 121ms/step - loss: 0.0192 - mse: 0.0192 - mae: 0.0963 - mape: 16913.5914 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0603 - val_mape: 21.0515\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 3s 114ms/step - loss: 0.0164 - mse: 0.0164 - mae: 0.0851 - mape: 85260.7319 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0557 - val_mape: 19.3104\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 3s 106ms/step - loss: 0.0145 - mse: 0.0145 - mae: 0.0829 - mape: 22103.8382 - val_loss: 0.0079 - val_mse: 0.0079 - val_mae: 0.0595 - val_mape: 19.6501\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 3s 106ms/step - loss: 0.0126 - mse: 0.0126 - mae: 0.0788 - mape: 130466.9107 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0558 - val_mape: 19.3826\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 3s 107ms/step - loss: 0.0141 - mse: 0.0141 - mae: 0.0781 - mape: 37637.7361 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0581 - val_mape: 21.7839\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 3s 108ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0771 - mape: 79455.2207 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0753 - val_mape: 21.1306\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 3s 105ms/step - loss: 0.0136 - mse: 0.0136 - mae: 0.0825 - mape: 49821.7295 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0697 - val_mape: 20.3544\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 3s 119ms/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0768 - mape: 4684.7714 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0616 - val_mape: 22.2517\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 3s 112ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0802 - mape: 32134.5635 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0552 - val_mape: 19.8728\n",
      "Time elapsed: 52.76 sec.\n",
      "Done training a model!\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_4_input'), name='conv1d_4_input', description=\"created by layer 'conv1d_4_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_4_input'), name='conv1d_4_input', description=\"created by layer 'conv1d_4_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "16/27 [================>.............] - ETA: 0s - loss: 0.1806 - mse: 0.1806 - mae: 0.3139 - mape: 88.8254 WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_4_input'), name='conv1d_4_input', description=\"created by layer 'conv1d_4_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - 1s 15ms/step - loss: 0.1487 - mse: 0.1487 - mae: 0.2756 - mape: 25664.6137 - val_loss: 0.0142 - val_mse: 0.0142 - val_mae: 0.0900 - val_mape: 29.2475\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0093 - mse: 0.0093 - mae: 0.0816 - mape: 425568.3677 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0578 - val_mape: 20.5636\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0525 - mape: 28134.4771 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0523 - val_mape: 18.6005\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0454 - mape: 12290.9481 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0534 - val_mape: 18.9075\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0464 - mape: 23625.3500 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0507 - val_mape: 17.4564\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0441 - mape: 22862.9678 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0515 - val_mape: 18.0256\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0440 - mape: 6768.7469 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0504 - val_mape: 17.1586\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0433 - mape: 7297.5065 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0516 - val_mape: 18.0666\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0423 - mape: 24464.1346 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0505 - val_mape: 17.4506\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0430 - mape: 39313.4742 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0547 - val_mape: 19.2139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d733b08880>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model with 7 layer lstm\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=1)) # Prediction of the next closing value\n",
    "\n",
    "generations = 10 # The higher the value the better the result\n",
    "start_timer = timer()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)\n",
    "end_timer = timer()\n",
    "print(f'Time elapsed: {str(end_timer - start_timer)[:5]} sec.')\n",
    "print('Done training a model!')\n",
    "#model with 2 layer cnn\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "model2.add(Convolution1D(32, 3))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "model2.add(Flatten())\n",
    "generations = 10\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model2.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with 7 layer lstm\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=1)) # Prediction of the next closing value\n",
    "\n",
    "generations = 10 # The higher the value the better the result\n",
    "start_timer = timer()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)\n",
    "end_timer = timer()\n",
    "print(f'Time elapsed: {str(end_timer - start_timer)[:5]} sec.')\n",
    "print('Done training a model!')\n",
    "#model with 3 layer cnn\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(LSTM(100, return_sequences=True))\n",
    "#model2.add(Dropout(0.2))\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(32, 3))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "model2.add(Flatten())\n",
    "#model2.add(Dense(1))\n",
    "#model.add(Activation('linear'))\n",
    "generations = 10\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model2.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with 7 layer lstm\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=1)) # Prediction of the next closing value\n",
    "\n",
    "generations = 10 # The higher the value the better the result\n",
    "start_timer = timer()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)\n",
    "end_timer = timer()\n",
    "print(f'Time elapsed: {str(end_timer - start_timer)[:5]} sec.')\n",
    "print('Done training a model!')\n",
    "#model with 4 layer cnn\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(LSTM(100, return_sequences=True))\n",
    "#model2.add(Dropout(0.2))\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(32, 3))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "model2.add(Flatten())\n",
    "#model2.add(Dense(1))\n",
    "#model.add(Activation('linear'))\n",
    "generations = 10\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model2.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_38_input'), name='lstm_38_input', description=\"created by layer 'lstm_38_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_38_input'), name='lstm_38_input', description=\"created by layer 'lstm_38_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0983 - mse: 0.0983 - mae: 0.2237 - mape: 59417.1960WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_38_input'), name='lstm_38_input', description=\"created by layer 'lstm_38_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - 23s 272ms/step - loss: 0.0968 - mse: 0.0968 - mae: 0.2217 - mape: 58036.9355 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0985 - val_mape: 28.8515\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 3s 122ms/step - loss: 0.0184 - mse: 0.0184 - mae: 0.0964 - mape: 9161.6038 - val_loss: 0.0159 - val_mse: 0.0159 - val_mae: 0.0842 - val_mape: 27.2375\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 3s 122ms/step - loss: 0.0166 - mse: 0.0166 - mae: 0.0900 - mape: 8331.1260 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0588 - val_mape: 20.0458\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 3s 121ms/step - loss: 0.0163 - mse: 0.0163 - mae: 0.0871 - mape: 121367.9828 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0625 - val_mape: 22.5906\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 3s 121ms/step - loss: 0.0146 - mse: 0.0146 - mae: 0.0850 - mape: 356353.2472 - val_loss: 0.0079 - val_mse: 0.0079 - val_mae: 0.0613 - val_mape: 19.7279\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 3s 120ms/step - loss: 0.0143 - mse: 0.0143 - mae: 0.0819 - mape: 1162.1908 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0589 - val_mape: 21.0282\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 3s 121ms/step - loss: 0.0139 - mse: 0.0139 - mae: 0.0810 - mape: 57206.0186 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0596 - val_mape: 22.9786\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 3s 121ms/step - loss: 0.0125 - mse: 0.0125 - mae: 0.0779 - mape: 76196.9024 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0583 - val_mape: 20.8695\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 3s 121ms/step - loss: 0.0116 - mse: 0.0116 - mae: 0.0752 - mape: 42515.7219 - val_loss: 0.0210 - val_mse: 0.0210 - val_mae: 0.1112 - val_mape: 35.7200\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 3s 120ms/step - loss: 0.0116 - mse: 0.0116 - mae: 0.0758 - mape: 1139.8406 - val_loss: 0.0195 - val_mse: 0.0195 - val_mae: 0.1068 - val_mape: 35.7369\n",
      "Time elapsed: 52.45 sec.\n",
      "Done training a model!\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_15_input'), name='conv1d_15_input', description=\"created by layer 'conv1d_15_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_15_input'), name='conv1d_15_input', description=\"created by layer 'conv1d_15_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "24/27 [=========================>....] - ETA: 0s - loss: 0.0608 - mse: 0.0608 - mae: 0.1579 - mape: 47936.6124WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_15_input'), name='conv1d_15_input', description=\"created by layer 'conv1d_15_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - 2s 23ms/step - loss: 0.0562 - mse: 0.0562 - mae: 0.1501 - mape: 43853.7859 - val_loss: 0.0094 - val_mse: 0.0094 - val_mae: 0.0609 - val_mape: 19.6257\n",
      "Epoch 2/20\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0473 - mape: 7734.5996 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0514 - val_mape: 15.7989\n",
      "Epoch 3/20\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0500 - mape: 47774.9612 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0485 - val_mape: 16.5365\n",
      "Epoch 4/20\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0434 - mape: 11851.7771 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0483 - val_mape: 16.8400\n",
      "Epoch 5/20\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0411 - mape: 32344.6864 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0518 - val_mape: 17.5135\n",
      "Epoch 6/20\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0400 - mape: 22289.4141 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0425 - val_mape: 13.8907\n",
      "Epoch 7/20\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0402 - mape: 17120.4740 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0414 - val_mape: 13.4910\n",
      "Epoch 8/20\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0391 - mape: 14524.4536 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0397 - val_mape: 12.8911\n",
      "Epoch 9/20\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0375 - mape: 12966.4205 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0556 - val_mape: 18.0447\n",
      "Epoch 10/20\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0387 - mape: 9513.1886 - val_loss: 0.0049 - val_mse: 0.0049 - val_mae: 0.0438 - val_mape: 12.8200\n",
      "Epoch 11/20\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0382 - mape: 14238.0391 - val_loss: 0.0047 - val_mse: 0.0047 - val_mae: 0.0430 - val_mape: 12.5027\n",
      "Epoch 12/20\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0455 - mape: 2891.4527 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0441 - val_mape: 14.7749\n",
      "Epoch 13/20\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0355 - mape: 26595.3034 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0504 - val_mape: 16.4067\n",
      "Epoch 14/20\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0365 - mape: 12058.3430 - val_loss: 0.0047 - val_mse: 0.0047 - val_mae: 0.0360 - val_mape: 11.4233\n",
      "Epoch 15/20\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0339 - mape: 3413.5473 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0348 - val_mape: 10.8435\n",
      "Epoch 16/20\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0342 - mape: 25837.8748 - val_loss: 0.0049 - val_mse: 0.0049 - val_mae: 0.0396 - val_mape: 13.1656\n",
      "Epoch 17/20\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0357 - mape: 3719.4143 - val_loss: 0.0045 - val_mse: 0.0045 - val_mae: 0.0372 - val_mape: 12.4380\n",
      "Epoch 18/20\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0329 - mape: 24463.8740 - val_loss: 0.0041 - val_mse: 0.0041 - val_mae: 0.0337 - val_mape: 10.7340\n",
      "Epoch 19/20\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0322 - mape: 27791.2248 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0320 - val_mape: 10.0050\n",
      "Epoch 20/20\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0304 - mape: 4890.2653 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0321 - val_mape: 9.9418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d731a32100>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model with 7 layer lstm\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=1)) # Prediction of the next closing value\n",
    "\n",
    "generations = 10 # The higher the value the better the result\n",
    "start_timer = timer()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)\n",
    "end_timer = timer()\n",
    "print(f'Time elapsed: {str(end_timer - start_timer)[:5]} sec.')\n",
    "print('Done training a model!')\n",
    "#model with 5 layer cnn\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "#model.add(LSTM(100, return_sequences=True))\n",
    "#model2.add(Dropout(0.2))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(32, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Flatten())\n",
    "#model2.add(Dense(1))\n",
    "#model.add(Activation('linear'))\n",
    "generations = 20\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model2.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_30_input'), name='lstm_30_input', description=\"created by layer 'lstm_30_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_30_input'), name='lstm_30_input', description=\"created by layer 'lstm_30_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1029 - mse: 0.1029 - mae: 0.2304 - mape: 64258.2525WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_30_input'), name='lstm_30_input', description=\"created by layer 'lstm_30_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - 29s 294ms/step - loss: 0.1014 - mse: 0.1014 - mae: 0.2285 - mape: 67050.1620 - val_loss: 0.0146 - val_mse: 0.0146 - val_mae: 0.0821 - val_mape: 29.8953\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 4s 148ms/step - loss: 0.0171 - mse: 0.0171 - mae: 0.0905 - mape: 78862.4612 - val_loss: 0.0170 - val_mse: 0.0170 - val_mae: 0.0882 - val_mape: 28.4541\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 4s 133ms/step - loss: 0.0130 - mse: 0.0130 - mae: 0.0794 - mape: 65178.8253 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0690 - val_mape: 23.9075\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 3s 126ms/step - loss: 0.0153 - mse: 0.0153 - mae: 0.0853 - mape: 68901.2288 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0600 - val_mape: 21.3856\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 3s 126ms/step - loss: 0.0155 - mse: 0.0155 - mae: 0.0870 - mape: 7894.8613 - val_loss: 0.0207 - val_mse: 0.0207 - val_mae: 0.1046 - val_mape: 32.9816\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 4s 151ms/step - loss: 0.0169 - mse: 0.0169 - mae: 0.0889 - mape: 132503.2656 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0595 - val_mape: 19.8218\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 4s 132ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0779 - mape: 69272.0382 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0591 - val_mape: 21.4029\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 3s 125ms/step - loss: 0.0128 - mse: 0.0128 - mae: 0.0795 - mape: 10590.2719 - val_loss: 0.0181 - val_mse: 0.0181 - val_mae: 0.0958 - val_mape: 31.3047\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 3s 125ms/step - loss: 0.0116 - mse: 0.0116 - mae: 0.0759 - mape: 3661.2376 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0689 - val_mape: 20.6670\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 3s 125ms/step - loss: 0.0128 - mse: 0.0128 - mae: 0.0788 - mape: 14426.4667 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0701 - val_mape: 25.3879\n",
      "Time elapsed: 61.46 sec.\n",
      "Done training a model!\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_13_input'), name='conv1d_13_input', description=\"created by layer 'conv1d_13_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_13_input'), name='conv1d_13_input', description=\"created by layer 'conv1d_13_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "15/27 [===============>..............] - ETA: 0s - loss: 0.1659 - mse: 0.1659 - mae: 0.2961 - mape: 28819.0385WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_13_input'), name='conv1d_13_input', description=\"created by layer 'conv1d_13_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - 1s 15ms/step - loss: 0.1328 - mse: 0.1328 - mae: 0.2545 - mape: 23096.3289 - val_loss: 0.0149 - val_mse: 0.0149 - val_mae: 0.0898 - val_mape: 30.8554\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0771 - mape: 128677.7984 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0569 - val_mape: 20.4004\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0494 - mape: 110098.4172 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0541 - val_mape: 19.3799\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0438 - mape: 30321.5276 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0522 - val_mape: 18.2820\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0441 - mape: 14981.7431 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0516 - val_mape: 17.8279\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0431 - mape: 11525.8349 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0516 - val_mape: 17.9472\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0452 - mape: 22469.8999 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0516 - val_mape: 17.9421\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0445 - mape: 2774.5057 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0513 - val_mape: 17.7367\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0450 - mape: 22135.6192 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0519 - val_mape: 18.1400\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0414 - mape: 3321.5122 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0515 - val_mape: 17.9176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d744536c70>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model with 8 layer lstm\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(units=1)) # Prediction of the next closing value\n",
    "\n",
    "generations = 10 # The higher the value the better the result\n",
    "start_timer = timer()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)\n",
    "end_timer = timer()\n",
    "print(f'Time elapsed: {str(end_timer - start_timer)[:5]} sec.')\n",
    "print('Done training a model!')\n",
    "#model with 2 layer cnn\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(LSTM(100, return_sequences=True))\n",
    "#model2.add(Dropout(0.2))\n",
    "model2.add(Convolution1D(32, 3))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "model2.add(Flatten())\n",
    "#model2.add(Dense(1))\n",
    "#model.add(Activation('linear'))\n",
    "generations = 10\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model2.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_45_input'), name='lstm_45_input', description=\"created by layer 'lstm_45_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_45_input'), name='lstm_45_input', description=\"created by layer 'lstm_45_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1086 - mse: 0.1086 - mae: 0.2437 - mape: 53999.9771WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_45_input'), name='lstm_45_input', description=\"created by layer 'lstm_45_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - 28s 315ms/step - loss: 0.1071 - mse: 0.1071 - mae: 0.2417 - mape: 56943.5834 - val_loss: 0.0183 - val_mse: 0.0183 - val_mae: 0.1248 - val_mape: 36.0554\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 4s 143ms/step - loss: 0.0245 - mse: 0.0245 - mae: 0.1117 - mape: 6494.1455 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0685 - val_mape: 24.9851\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 4s 135ms/step - loss: 0.0204 - mse: 0.0204 - mae: 0.0979 - mape: 58009.3360 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0601 - val_mape: 21.4422\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 4s 135ms/step - loss: 0.0185 - mse: 0.0185 - mae: 0.0937 - mape: 76170.9388 - val_loss: 0.0186 - val_mse: 0.0186 - val_mae: 0.0960 - val_mape: 30.7711\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 4s 135ms/step - loss: 0.0174 - mse: 0.0174 - mae: 0.0888 - mape: 62981.9003 - val_loss: 0.0268 - val_mse: 0.0268 - val_mae: 0.1305 - val_mape: 40.6971\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 0.0139 - mse: 0.0139 - mae: 0.0835 - mape: 5965.5876 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0577 - val_mape: 21.1010\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 0.0139 - mse: 0.0139 - mae: 0.0821 - mape: 123546.7260 - val_loss: 0.0142 - val_mse: 0.0142 - val_mae: 0.0764 - val_mape: 25.8139\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 0.0135 - mse: 0.0135 - mae: 0.0812 - mape: 2992.4630 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0597 - val_mape: 19.5723\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 0.0143 - mse: 0.0143 - mae: 0.0850 - mape: 261.2391 - val_loss: 0.0087 - val_mse: 0.0087 - val_mae: 0.0559 - val_mape: 20.2407\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 0.0141 - mse: 0.0141 - mae: 0.0813 - mape: 131126.4590 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0549 - val_mape: 19.2391\n",
      "Time elapsed: 61.18 sec.\n",
      "Done training a model!\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_20_input'), name='conv1d_20_input', description=\"created by layer 'conv1d_20_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_20_input'), name='conv1d_20_input', description=\"created by layer 'conv1d_20_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "22/27 [=======================>......] - ETA: 0s - loss: 0.1112 - mse: 0.1112 - mae: 0.2309 - mape: 57956.8782WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_20_input'), name='conv1d_20_input', description=\"created by layer 'conv1d_20_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.0985 - mse: 0.0985 - mae: 0.2123 - mape: 66748.1560 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0768 - val_mape: 22.2008\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0549 - mape: 1967.5393 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0544 - val_mape: 18.8572\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0413 - mape: 6238.7699 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0522 - val_mape: 18.2523\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0404 - mape: 18619.8507 - val_loss: 0.0087 - val_mse: 0.0087 - val_mae: 0.0526 - val_mape: 18.3564\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0423 - mape: 54562.7415 - val_loss: 0.0088 - val_mse: 0.0088 - val_mae: 0.0533 - val_mape: 18.6559\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0438 - mape: 6742.3078 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0496 - val_mape: 17.1302\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0418 - mape: 9753.4208 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0488 - val_mape: 16.6749\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0423 - mape: 3876.9734 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0487 - val_mape: 16.1859\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0399 - mape: 12275.0731 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0554 - val_mape: 19.1568\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0414 - mape: 1701.8395 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0559 - val_mape: 19.3624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d7381852b0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model with 8 layer lstm\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(units=1)) # Prediction of the next closing value\n",
    "\n",
    "generations = 10 # The higher the value the better the result\n",
    "start_timer = timer()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)\n",
    "end_timer = timer()\n",
    "print(f'Time elapsed: {str(end_timer - start_timer)[:5]} sec.')\n",
    "print('Done training a model!')\n",
    "#model with 3 layer cnn\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(LSTM(100, return_sequences=True))\n",
    "#model2.add(Dropout(0.2))\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(32, 3))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "model2.add(Flatten())\n",
    "#model2.add(Dense(1))\n",
    "#model.add(Activation('linear'))\n",
    "generations = 10\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model2.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_53_input'), name='lstm_53_input', description=\"created by layer 'lstm_53_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_53_input'), name='lstm_53_input', description=\"created by layer 'lstm_53_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1166 - mse: 0.1166 - mae: 0.2523 - mape: 186792.6811WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_53_input'), name='lstm_53_input', description=\"created by layer 'lstm_53_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - 27s 303ms/step - loss: 0.1150 - mse: 0.1150 - mae: 0.2501 - mape: 182929.8864 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0989 - val_mape: 30.4697\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 4s 144ms/step - loss: 0.0234 - mse: 0.0234 - mae: 0.1071 - mape: 22106.2683 - val_loss: 0.0299 - val_mse: 0.0299 - val_mae: 0.1344 - val_mape: 39.1586\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 4s 144ms/step - loss: 0.0172 - mse: 0.0172 - mae: 0.0881 - mape: 68689.5571 - val_loss: 0.0117 - val_mse: 0.0117 - val_mae: 0.0892 - val_mape: 23.2986\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 4s 143ms/step - loss: 0.0210 - mse: 0.0210 - mae: 0.1038 - mape: 33686.2025 - val_loss: 0.0134 - val_mse: 0.0134 - val_mae: 0.0729 - val_mape: 24.9977\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 4s 144ms/step - loss: 0.0151 - mse: 0.0151 - mae: 0.0847 - mape: 5677.7413 - val_loss: 0.0140 - val_mse: 0.0140 - val_mae: 0.0757 - val_mape: 25.8826\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 4s 144ms/step - loss: 0.0134 - mse: 0.0134 - mae: 0.0841 - mape: 92220.1639 - val_loss: 0.0087 - val_mse: 0.0087 - val_mae: 0.0549 - val_mape: 19.7680\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 4s 144ms/step - loss: 0.0141 - mse: 0.0141 - mae: 0.0822 - mape: 2742.8178 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.0935 - val_mape: 30.6376\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 4s 147ms/step - loss: 0.0153 - mse: 0.0153 - mae: 0.0902 - mape: 81070.0614 - val_loss: 0.0149 - val_mse: 0.0149 - val_mae: 0.0821 - val_mape: 28.2956\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 4s 144ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0807 - mape: 6855.9375 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0611 - val_mape: 23.3117\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 4s 145ms/step - loss: 0.0133 - mse: 0.0133 - mae: 0.0842 - mape: 262566.2095 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0600 - val_mape: 21.0216\n",
      "Time elapsed: 62.45 sec.\n",
      "Done training a model!\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_23_input'), name='conv1d_23_input', description=\"created by layer 'conv1d_23_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_23_input'), name='conv1d_23_input', description=\"created by layer 'conv1d_23_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "23/27 [========================>.....] - ETA: 0s - loss: 0.0982 - mse: 0.0982 - mae: 0.2046 - mape: 22883.3048WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_23_input'), name='conv1d_23_input', description=\"created by layer 'conv1d_23_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - 2s 24ms/step - loss: 0.0880 - mse: 0.0880 - mae: 0.1895 - mape: 26355.6571 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0572 - val_mape: 17.8141\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0447 - mape: 2287.4099 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0460 - val_mape: 15.0049\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0406 - mape: 37636.3822 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0497 - val_mape: 16.9470\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0413 - mape: 16872.1368 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0471 - val_mape: 16.0019\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0401 - mape: 7694.0208 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0445 - val_mape: 15.0672\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0402 - mape: 26767.6924 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0431 - val_mape: 14.0822\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0424 - mape: 16567.6981 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0429 - val_mape: 14.2785\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0399 - mape: 64528.3131 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0447 - val_mape: 13.8313\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0424 - mape: 11651.9494 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0542 - val_mape: 18.0454\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0384 - mape: 8467.3196 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0421 - val_mape: 13.4906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d755c895b0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model with 8 layer lstm\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(units=1)) # Prediction of the next closing value\n",
    "\n",
    "generations = 10 # The higher the value the better the result\n",
    "start_timer = timer()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)\n",
    "end_timer = timer()\n",
    "print(f'Time elapsed: {str(end_timer - start_timer)[:5]} sec.')\n",
    "print('Done training a model!')\n",
    "#model with 4 layer cnn\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "#model.add(LSTM(100, return_sequences=True))\n",
    "#model2.add(Dropout(0.2))\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(32, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Flatten())\n",
    "#model2.add(Dense(1))\n",
    "#model.add(Activation('linear'))\n",
    "generations = 10\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model2.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_61_input'), name='lstm_61_input', description=\"created by layer 'lstm_61_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_61_input'), name='lstm_61_input', description=\"created by layer 'lstm_61_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0904 - mse: 0.0904 - mae: 0.2200 - mape: 65833.5259WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_61_input'), name='lstm_61_input', description=\"created by layer 'lstm_61_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - 30s 334ms/step - loss: 0.0893 - mse: 0.0893 - mae: 0.2185 - mape: 64305.2429 - val_loss: 0.0254 - val_mse: 0.0254 - val_mae: 0.1247 - val_mape: 40.1230\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 4s 149ms/step - loss: 0.0224 - mse: 0.0224 - mae: 0.1046 - mape: 68918.3931 - val_loss: 0.0328 - val_mse: 0.0328 - val_mae: 0.1456 - val_mape: 43.1552\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 4s 157ms/step - loss: 0.0207 - mse: 0.0207 - mae: 0.0967 - mape: 45274.3269 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0584 - val_mape: 20.3868\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 4s 143ms/step - loss: 0.0154 - mse: 0.0154 - mae: 0.0858 - mape: 2335.9364 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0613 - val_mape: 20.5306\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 4s 142ms/step - loss: 0.0172 - mse: 0.0172 - mae: 0.0914 - mape: 582.9128 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0727 - val_mape: 21.2223\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 4s 142ms/step - loss: 0.0155 - mse: 0.0155 - mae: 0.0844 - mape: 2374.6996 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0616 - val_mape: 20.0064\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 4s 142ms/step - loss: 0.0137 - mse: 0.0137 - mae: 0.0795 - mape: 12900.7020 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0577 - val_mape: 20.8529\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 4s 144ms/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0750 - mape: 39608.5067 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0702 - val_mape: 25.8718\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 4s 143ms/step - loss: 0.0116 - mse: 0.0116 - mae: 0.0766 - mape: 11025.2830 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0563 - val_mape: 20.3449\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0756 - mape: 373414.1939 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0546 - val_mape: 19.3761\n",
      "Time elapsed: 65.51 sec.\n",
      "Done training a model!\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_27_input'), name='conv1d_27_input', description=\"created by layer 'conv1d_27_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_27_input'), name='conv1d_27_input', description=\"created by layer 'conv1d_27_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "23/27 [========================>.....] - ETA: 0s - loss: 0.0798 - mse: 0.0798 - mae: 0.1836 - mape: 48476.8806WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_27_input'), name='conv1d_27_input', description=\"created by layer 'conv1d_27_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - 2s 28ms/step - loss: 0.0717 - mse: 0.0717 - mae: 0.1708 - mape: 49435.9277 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0619 - val_mape: 19.7731\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0460 - mape: 15893.2047 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0576 - val_mape: 16.3912\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0494 - mape: 987.4101 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0442 - val_mape: 14.6670\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0415 - mape: 54782.2044 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0439 - val_mape: 14.5302\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0392 - mape: 2085.0743 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0440 - val_mape: 14.9014\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0420 - mape: 4433.8340 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0488 - val_mape: 16.5607\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0433 - mape: 61295.3854 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0434 - val_mape: 14.5414\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0418 - mape: 24541.4276 - val_loss: 0.0088 - val_mse: 0.0088 - val_mae: 0.0575 - val_mape: 18.4093\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0393 - mape: 16762.4838 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0492 - val_mape: 16.5240\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0360 - mape: 26447.9769 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0405 - val_mape: 13.4458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d73e4c2fa0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model with 8 layer lstm\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(units=1)) # Prediction of the next closing value\n",
    "\n",
    "generations = 10 # The higher the value the better the result\n",
    "start_timer = timer()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)\n",
    "end_timer = timer()\n",
    "print(f'Time elapsed: {str(end_timer - start_timer)[:5]} sec.')\n",
    "print('Done training a model!')\n",
    "#model with 5 layer cnn\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "#model.add(LSTM(100, return_sequences=True))\n",
    "#model2.add(Dropout(0.2))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(32, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Flatten())\n",
    "#model2.add(Dense(1))\n",
    "#model.add(Activation('linear'))\n",
    "generations = 10\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model2.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with 9 layer lstm\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(units=1)) # Prediction of the next closing value\n",
    "\n",
    "generations = 10 # The higher the value the better the result\n",
    "start_timer = timer()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)\n",
    "end_timer = timer()\n",
    "print(f'Time elapsed: {str(end_timer - start_timer)[:5]} sec.')\n",
    "print('Done training a model!')\n",
    "#model with 2 layer cnn\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "#model.add(LSTM(100, return_sequences=True))\n",
    "#model2.add(Dropout(0.2))\n",
    "model2.add(Convolution1D(32, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Flatten())\n",
    "#model2.add(Dense(1))\n",
    "#model.add(Activation('linear'))\n",
    "generations = 10\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model2.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with 9 layer lstm\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(units=1)) # Prediction of the next closing value\n",
    "\n",
    "generations = 10 # The higher the value the better the result\n",
    "start_timer = timer()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)\n",
    "end_timer = timer()\n",
    "print(f'Time elapsed: {str(end_timer - start_timer)[:5]} sec.')\n",
    "print('Done training a model!')\n",
    "#model with 3 layer cnn\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "#model.add(LSTM(100, return_sequences=True))\n",
    "#model2.add(Dropout(0.2))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(32, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Flatten())\n",
    "#model2.add(Dense(1))\n",
    "#model.add(Activation('linear'))\n",
    "generations = 10\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model2.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with 9 layer lstm\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(units=1)) # Prediction of the next closing value\n",
    "\n",
    "generations = 10 # The higher the value the better the result\n",
    "start_timer = timer()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)\n",
    "end_timer = timer()\n",
    "print(f'Time elapsed: {str(end_timer - start_timer)[:5]} sec.')\n",
    "print('Done training a model!')\n",
    "#model with 4 layer cnn\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "#model.add(LSTM(100, return_sequences=True))\n",
    "#model2.add(Dropout(0.2))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(32, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Flatten())\n",
    "#model2.add(Dense(1))\n",
    "#model.add(Activation('linear'))\n",
    "generations = 10\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model2.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_21_input'), name='lstm_21_input', description=\"created by layer 'lstm_21_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_21_input'), name='lstm_21_input', description=\"created by layer 'lstm_21_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1157 - mse: 0.1157 - mae: 0.2570 - mape: 139477.0385WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_21_input'), name='lstm_21_input', description=\"created by layer 'lstm_21_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - 32s 329ms/step - loss: 0.1141 - mse: 0.1141 - mae: 0.2548 - mape: 141526.4306 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0757 - val_mape: 29.6958\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 4s 137ms/step - loss: 0.0234 - mse: 0.0234 - mae: 0.1091 - mape: 103073.4999 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0701 - val_mape: 24.8121\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 4s 137ms/step - loss: 0.0178 - mse: 0.0178 - mae: 0.0911 - mape: 109250.7932 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0601 - val_mape: 21.0975\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 4s 136ms/step - loss: 0.0147 - mse: 0.0147 - mae: 0.0844 - mape: 499.8454 - val_loss: 0.0234 - val_mse: 0.0234 - val_mae: 0.1127 - val_mape: 34.7232\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 4s 136ms/step - loss: 0.0164 - mse: 0.0164 - mae: 0.0877 - mape: 51861.9706 - val_loss: 0.0445 - val_mse: 0.0445 - val_mae: 0.1755 - val_mape: 49.6756\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 4s 136ms/step - loss: 0.0157 - mse: 0.0157 - mae: 0.0869 - mape: 141876.2736 - val_loss: 0.0289 - val_mse: 0.0289 - val_mae: 0.1329 - val_mape: 39.7920\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 4s 136ms/step - loss: 0.0136 - mse: 0.0136 - mae: 0.0826 - mape: 12278.7139 - val_loss: 0.0450 - val_mse: 0.0450 - val_mae: 0.1777 - val_mape: 50.4589\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 4s 136ms/step - loss: 0.0173 - mse: 0.0173 - mae: 0.0928 - mape: 110004.9827 - val_loss: 0.0241 - val_mse: 0.0241 - val_mae: 0.1171 - val_mape: 36.1612\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 4s 136ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0797 - mape: 114295.1665 - val_loss: 0.0172 - val_mse: 0.0172 - val_mae: 0.0907 - val_mape: 30.0122\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 4s 136ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0770 - mape: 414.8561 - val_loss: 0.0164 - val_mse: 0.0164 - val_mae: 0.0862 - val_mape: 28.1977\n",
      "Time elapsed: 65.53 sec.\n",
      "Done training a model!\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_8_input'), name='conv1d_8_input', description=\"created by layer 'conv1d_8_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_8_input'), name='conv1d_8_input', description=\"created by layer 'conv1d_8_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0819 - mse: 0.0819 - mae: 0.1808 - mape: 59582.6795WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='conv1d_8_input'), name='conv1d_8_input', description=\"created by layer 'conv1d_8_input'\"), but it was called on an input with incompatible shape (None, 21, 1).\n",
      "27/27 [==============================] - 2s 25ms/step - loss: 0.0787 - mse: 0.0787 - mae: 0.1759 - mape: 59340.9373 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0626 - val_mape: 19.5575\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0457 - mape: 11667.7312 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0461 - val_mape: 15.4938\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0393 - mape: 93188.3122 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0542 - val_mape: 17.9945\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0411 - mape: 2030.9509 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0439 - val_mape: 14.7529\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0428 - mape: 64273.4566 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0424 - val_mape: 13.9438\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0421 - mape: 1194.4980 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0639 - val_mape: 20.5045\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0423 - mape: 15329.3522 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0412 - val_mape: 13.5652\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0379 - mape: 34028.0957 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0424 - val_mape: 14.0984\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0388 - mape: 21175.2322 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0505 - val_mape: 14.3126\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0412 - mape: 13280.7576 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0512 - val_mape: 16.7840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d73cca04f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model with 9 layer lstm\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(units=1)) # Prediction of the next closing value\n",
    "\n",
    "generations = 10 # The higher the value the better the result\n",
    "start_timer = timer()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)\n",
    "end_timer = timer()\n",
    "print(f'Time elapsed: {str(end_timer - start_timer)[:5]} sec.')\n",
    "print('Done training a model!')\n",
    "#model with 5 layer cnn\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "#model.add(LSTM(100, return_sequences=True))\n",
    "#model2.add(Dropout(0.2))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(32, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Flatten())\n",
    "#model2.add(Dense(1))\n",
    "#model.add(Activation('linear'))\n",
    "generations = 10\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model2.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with 10 layer lstm\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(units=1)) # Prediction of the next closing value\n",
    "\n",
    "generations = 10 # The higher the value the better the result\n",
    "start_timer = timer()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)\n",
    "end_timer = timer()\n",
    "print(f'Time elapsed: {str(end_timer - start_timer)[:5]} sec.')\n",
    "print('Done training a model!')\n",
    "#model with 2 layer cnn\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "#model.add(LSTM(100, return_sequences=True))\n",
    "#model2.add(Dropout(0.2))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(32, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Flatten())\n",
    "#model2.add(Dense(1))\n",
    "#model.add(Activation('linear'))\n",
    "generations = 10\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model2.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with 10 layer lstm\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(units=1)) # Prediction of the next closing value\n",
    "\n",
    "generations = 10 # The higher the value the better the result\n",
    "start_timer = timer()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)\n",
    "end_timer = timer()\n",
    "print(f'Time elapsed: {str(end_timer - start_timer)[:5]} sec.')\n",
    "print('Done training a model!')\n",
    "#model with 3 layer cnn\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "#model.add(LSTM(100, return_sequences=True))\n",
    "#model2.add(Dropout(0.2))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(32, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Flatten())\n",
    "#model2.add(Dense(1))\n",
    "#model.add(Activation('linear'))\n",
    "generations = 10\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model2.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with 10 layer lstm\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(units=1)) # Prediction of the next closing value\n",
    "\n",
    "generations = 10 # The higher the value the better the result\n",
    "start_timer = timer()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)\n",
    "end_timer = timer()\n",
    "print(f'Time elapsed: {str(end_timer - start_timer)[:5]} sec.')\n",
    "print('Done training a model!')\n",
    "#model with 4 layer cnn\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "#model.add(LSTM(100, return_sequences=True))\n",
    "#model2.add(Dropout(0.2))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(32, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Flatten())\n",
    "#model2.add(Dense(1))\n",
    "#model.add(Activation('linear'))\n",
    "generations = 10\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model2.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with 10 layer lstm\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[0], 1)))\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(units=1)) # Prediction of the next closing value\n",
    "\n",
    "generations = 10 # The higher the value the better the result\n",
    "start_timer = timer()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)\n",
    "end_timer = timer()\n",
    "print(f'Time elapsed: {str(end_timer - start_timer)[:5]} sec.')\n",
    "print('Done training a model!')\n",
    "#model with 5 layer cnn\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution1D(64, 3, input_shape=(X_train.shape[0], 1)))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "#model.add(LSTM(100, return_sequences=True))\n",
    "#model2.add(Dropout(0.2))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(64, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Convolution1D(32, 3))\n",
    "model2.add(MaxPooling1D(pool_size=1))\n",
    "model2.add(Flatten())\n",
    "#model2.add(Dense(1))\n",
    "#model.add(Activation('linear'))\n",
    "generations = 10\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','mae','mape'])\n",
    "model2.fit(X_train,y_train, epochs=generations, batch_size=32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop1=['number']\n",
    "Mineral_test.drop(to_drop1,inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1075, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1075, 1), dtype=tf.float32, name='lstm_61_input'), name='lstm_61_input', description=\"created by layer 'lstm_61_input'\"), but it was called on an input with incompatible shape (32, 21, 1).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#third code\n",
    "y_test=[]\n",
    "real_stock_price = Mineral_test.iloc[:, 1:2].values\n",
    "sc1 = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc1.fit_transform(real_stock_price)\n",
    "\n",
    "# Getting the predicted stock price of 2017\n",
    "# We need 60 previous inputs for each day of the Test_set in 2017\n",
    "# Combine 'dataset_train' and 'dataset_test'\n",
    "# 'axis = 0' for Vertical Concatenation to add rows to the bottom\n",
    "dataset_total = pd.concat((Mineral_train['close'],Mineral_test['close']), axis = 0)\n",
    "# Extract Stock Prices for Test time period, plus 60 days previous\n",
    "inputs = dataset_total[len(dataset_total) - len(Mineral_test) - 21:].values\n",
    "# 'reshape' function to get it into a NumPy format\n",
    "inputs = inputs.reshape(-1,1)\n",
    "# Inputs need to be scaled to match the model trained on Scaled Feature\n",
    "inputs = sc.transform(inputs)\n",
    "# The following is pasted from above and modified for Testing, romove all 'Ys'\n",
    "X_test = []\n",
    "\n",
    "for i in range(21, 469 ):\n",
    "    X_test.append(inputs[i-21:i, 0])\n",
    "    y_test.append(inputs[i, 0])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "# We need a 3D input so add another dimension\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "# Predict the Stock Price\n",
    "predicted_stock_price = model.predict(X_test)\n",
    "# We need to inverse the scaling of our prediction to get a Dollar amount\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "\n",
    "# Visualising the results\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real Petroleum Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Petroleum Stock Price')\n",
    "plt.title('non-metalic Stock Price Prediction')\n",
    "plt.xlabel('Time (day)')\n",
    "plt.ylabel('Petroleum Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ind2['low'].plot(kind='hist');\n",
    "plt.ylabel('Number')\n",
    "plt.xlabel('columns')\n",
    "plt.title('Non-metallic minerals group')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
